# 一，MongoDB复制集 #
MongoDB复制是将数据同步在多个服务器的过程。

复制提供了数据的冗余备份，并在多个服务器上存储数据副本，提高了数据的可用性， 并可以保证数据的安全性。

复制还允许你从硬件故障和服务中断中恢复数据。

复制集：

 - 保障数据的安全性
 - 数据高可用性 (24*7)
 - 灾难恢复
 - 无需停机维护（如备份，重建索引，压缩）
 - 分布式读取数据

# 二，MongoDB原理 #
mongodb的复制至少需要两个节点。其中一个是主节点，负责处理客户端请求，其余的都是从节点，负责复制主节点上的数据。

mongodb各个节点常见的搭配方式为：一主一从、一主多从。

主节点记录在其上的所有操作oplog，从节点定期轮询主节点获取这些操作，然后对自己的数据副本执行这些操作，从而保证从节点的数据与主节点一致。

MongoDB复制结构图如下所示：

![](replica-set-read-write-operations-primary.png)

以上结构图中，客户端从主节点读取数据，在客户端写入数据到主节点时， 主节点与从节点进行数据交互保障数据的一致性。

特点：

 - N 个节点的集群
 - 任何节点可作为主节点
 - 所有写入操作都在主节点上
 - 自动故障转移
 - 自动恢复

# 三，MongoDB复制集原理 #

主节点（primary）：负责数据的读写，将数据同步到从节点，并参与投票。

从节点（secondary）：负责从主节点同步数据，参与投票。

仲裁者节点（arbiter）：只负责参与投票，不同步数据。

一个复制集至少需要三个节点，常见的两种复制集形式为一主两从或一主一从一仲裁。

一主两从：

![](replica-set-primary-with-two-secondaries.png)

一主一从一仲裁：

![](replica-set-primary-with-secondary-and-arbiter.png)

自动故障转移：当主节点发生故障时，剩下的节点能够通过选举，选举出新的主节点。

![](replica-set-trigger-election.png)

# 四，部署复制集 #
这里使用Windows平台部署，基于MongoDB 3.4版本，部署常见的一主一从一仲裁的简单复制集架构。

创建复制集中每个节点存放数据的目录。

    D:\MongoDB\Server\3.4\data\Replication\db_rs0
	D:\MongoDB\Server\3.4\data\Replication\db_rs1
	D:\MongoDB\Server\3.4\data\Replication\db_rs2

创建复制集中的每个节点启动时所需的配置文件。

	D:\MongoDB\Server\3.4\data\Replication\db_rs0\configs_rs0\rs0_0.conf
	D:\MongoDB\Server\3.4\data\Replication\db_rs0\configs_rs0\rs0_1.conf
	D:\MongoDB\Server\3.4\data\Replication\db_rs0\configs_rs0\rs0_2.conf

每个配置文件对应的内容

rs0_0.conf

    dbpath = D:\MongoDB\Server\3.4\data\Replication\db_rs0\rs0_0
    logpath = D:\MongoDB\Server\3.4\data\Replication\db_rs0\log\rs0_0.log
    journal = true
    port = 40000
    replSet = rs0

rs0_1.conf

    dbpath = D:\MongoDB\Server\3.4\data\Replication\db_rs0\rs0_1
    logpath = D:\MongoDB\Server\3.4\data\Replication\db_rs0\log\rs0_1.log
    journal = true
    port = 40000
    replSet = rs0

rs0_2.conf

    dbpath = D:\MongoDB\Server\3.4\data\Replication\db_rs0\rs0_2
    logpath = D:\MongoDB\Server\3.4\data\Replication\db_rs0\log\rs0_2.log
    journal = true
    port = 40000
    replSet = rs0

启动上面三个节点对应的MongoDB实例。

    mongod -config D:\MongoDB\Server\3.4\data\Replication\db_rs0\configs_rs0\rs0_0.conf
	mongod -config D:\MongoDB\Server\3.4\data\Replication\db_rs0\configs_rs0\rs0_1.conf
	mongod -config D:\MongoDB\Server\3.4\data\Replication\db_rs0\configs_rs0\rs0_2.conf

现在已经启动了3个实例，但是复制集还没配置好，如上图所描述的那样，我们应该通过配置确定哪个节点为primary，哪个节点为secondary，哪个节点是arbiter。

启动一个mongo客户端，连接到上面的一个mongod实例。

	mongo -port 40000

复制集初始化，在shell中执行命令。

	rs.initiate()
	{
        "info2" : "no configuration specified. Using a default configuration for the set",
        "me" : "��վ-�¿���:40000",
        "ok" : 1
	}

查看当前配置。

	rs.conf()
	{
    "_id" : "rs0",
    "version" : 1,
    "protocolVersion" : NumberLong(1),
    "members" : [ 
        {
            "_id" : 0,
            "host" : "��վ-�¿���:40000",
            "arbiterOnly" : false,
            "buildIndexes" : true,
            "hidden" : false,
            "priority" : 1.0,
            "tags" : {},
            "slaveDelay" : NumberLong(0),
            "votes" : 1
        }
    ],
    "settings" : {
        "chainingAllowed" : true,
        "heartbeatIntervalMillis" : 2000,
        "heartbeatTimeoutSecs" : 10,
        "electionTimeoutMillis" : 10000,
        "catchUpTimeoutMillis" : 2000,
        "getLastErrorModes" : {},
        "getLastErrorDefaults" : {
            "w" : 1,
            "wtimeout" : 0
        },
        "replicaSetId" : ObjectId("598d1a8786256296a78a4694")
    }
	}

执行初始化的mongo实例默认成为复制集的primary节点，可以看到，当前复制集只有一个primary节点。

在监听40000端口的实例的shell添加复制集中的secondary节点。

    rs0:PRIMARY> rs.add("10.32.8.78:40001")
    { "ok" : 1 }

在监听40000端口的实例的shell添加复制集中的arbiter节点。

    rs0:PRIMARY> rs.addArb("10.32.8.78:40002")
    { "ok" : 1 }

再次查看配置

	rs.conf()
	{
    "_id" : "rs0",
    "version" : 3,
    "protocolVersion" : NumberLong(1),
    "members" : [ 
        {
            "_id" : 0,
            "host" : "��վ-�¿���:40000",
            "arbiterOnly" : false,
            "buildIndexes" : true,
            "hidden" : false,
            "priority" : 1.0,
            "tags" : {},
            "slaveDelay" : NumberLong(0),
            "votes" : 1
        }, 
        {
            "_id" : 1,
            "host" : "10.32.8.78:40001",
            "arbiterOnly" : false,
            "buildIndexes" : true,
            "hidden" : false,
            "priority" : 1.0,
            "tags" : {},
            "slaveDelay" : NumberLong(0),
            "votes" : 1
        }, 
        {
            "_id" : 2,
            "host" : "10.32.8.78:40002",
            "arbiterOnly" : true,
            "buildIndexes" : true,
            "hidden" : false,
            "priority" : 1.0,
            "tags" : {},
            "slaveDelay" : NumberLong(0),
            "votes" : 1
        }
    ],
    "settings" : {
        "chainingAllowed" : true,
        "heartbeatIntervalMillis" : 2000,
        "heartbeatTimeoutSecs" : 10,
        "electionTimeoutMillis" : 10000,
        "catchUpTimeoutMillis" : 2000,
        "getLastErrorModes" : {},
        "getLastErrorDefaults" : {
            "w" : 1,
            "wtimeout" : 0
        },
        "replicaSetId" : ObjectId("598d1a8786256296a78a4694")
    }
	}

可以看到有三个节点了。

查看主节点。

	rs.isMaster()
	rs0:PRIMARY> rs.isMaster()
	{
        "hosts" : [
                "��վ-�¿���:40000",
                "10.32.8.78:40001"
        ],
        "arbiters" : [
                "10.32.8.78:40002"
        ],
        "setName" : "rs0",
        "setVersion" : 3,
        "ismaster" : true,
        "secondary" : false,
        "primary" : "��վ-�¿���:40000",
        "me" : "��վ-�¿���:40000",
        "electionId" : ObjectId("7fffffff0000000000000001"),
        "lastWrite" : {
                "opTime" : {
                        "ts" : Timestamp(1502420582, 1),
                        "t" : NumberLong(1)
                },
                "lastWriteDate" : ISODate("2017-08-11T03:03:02Z")
        },
        "maxBsonObjectSize" : 16777216,
        "maxMessageSizeBytes" : 48000000,
        "maxWriteBatchSize" : 1000,
        "localTime" : ISODate("2017-08-11T03:03:10.381Z"),
        "maxWireVersion" : 5,
        "minWireVersion" : 0,
        "readOnly" : false,
        "ok" : 1
	}

此时在40000端口的实例插入测试数据。

    rs0:PRIMARY> db.getCollection('test').insert({age:1,name:'a'})
    WriteResult({ "nInserted" : 1 })

连接40001实例查看是否自动同步数据，**secondary默认是不允许读写的，所以要先执行slaveOk**，方法如下

    rs0:SECONDARY> rs.slaveOk()
    rs0:SECONDARY> db.getCollection('test').find({})
    { "_id" : ObjectId("598d1f2e0aec260c3b8c3bc2"), "age" : 1, "name" : "a" }
    rs0:SECONDARY>

此时，数据已经完成自动同步。

现在演示自动故障转移。

在40000端口的mongod实例中通过Ctrl+c中断进程，然后在在40001端口的mongo中查看复制集信息

    rs0:PRIMARY> rs.isMaster()
	{
        "hosts" : [
                "��վ-�¿���:40000",
                "10.32.8.78:40001"
        ],
        "arbiters" : [
                "10.32.8.78:40002"
        ],
        "setName" : "rs0",
        "setVersion" : 3,
        "ismaster" : true,
        "secondary" : false,
        "primary" : "10.32.8.78:40001",
        "me" : "10.32.8.78:40001",
        "electionId" : ObjectId("7fffffff0000000000000002"),
        "lastWrite" : {
                "opTime" : {
                        "ts" : Timestamp(1502431282, 1),
                        "t" : NumberLong(2)
                },
                "lastWriteDate" : ISODate("2017-08-11T06:01:22Z")
        },
        "maxBsonObjectSize" : 16777216,
        "maxMessageSizeBytes" : 48000000,
        "maxWriteBatchSize" : 1000,
        "localTime" : ISODate("2017-08-11T06:01:23.145Z"),
        "maxWireVersion" : 5,
        "minWireVersion" : 0,
        "readOnly" : false,
        "ok" : 1
	}

可以看到在40000实例中断后40001的实例通过投票被选举为新的primary节点，实现了故障自动转移。

# 五，读参考（Read Preference） #
读参考是指MongoDB将客户端的读请求路由到复制集中指定的成员上，默认情况下读操作的请求被路由到复制集的primary节点上。从primary节点上进行读取能够保证读到的数据是最新的，但是将读操作路由到其他secondary节点上去后，由于从primary节点同步数据到secondary节点会产生时间差，可能导致从secondary节点上读到的数据不是最新的。当然这对于实时性要求不是很高的绝大部分应用程序来说，并不是大问题。

因为每一个secondary节点都会从primary节点同步数据，所有secondary节点一般有相同的写操作流量，同时primary节点上的用于同步数据的读操作量也并没有减少。

它最大的好处是能够使客户端的读请求路由到最佳的secondary节点上（如最近的节点），提高客户端的读效率，并且一定程度上实现读写分离。

![](replica-set-read-preference.png)

# 六，写关注（Write Concern） #
对于某些应用程序来说，写关注是重要的。它能判断哪些写操作成功写入了，哪些失败了。对于失败的操作，驱动程序能返回错误，由应用程序决定怎么处理。如果没有写关注，应用程序发送一个写操作到socket后，就不会管后面发生了什么情况，不知道是否成功写入数据库，这种情形对于日志类型的应用程序还是可以接受的，因为偶尔的写失败不会影响整个日志的监控情况。带有写关注的操作会等到数据库确认成功写入后才能返回，因此写关注会带来一点性能的损失。

![](crud-write-concern-w2.png)

    db.products.insert(
       { item: "envelopes", qty : 100, type: "Clasp" },
       { writeConcern: { w: 2, wtimeout: 5000 } }
    )

w为2表示写关注将针对复制集中的2个节点，当MongoDB收到这些节点的反馈信息后，命令才返回给客户端继续执行。

wtimeout表示超时时间，指定写关注应在多长时间内返归，如果你没有指定这个值，复制集可能因为不确定因素导致应用程序的写操作一直阻塞。
